# Synthetic Data Platform

Enterprise-grade synthetic data generation system for analytics, ML, and privacy-safe testing.

## Features

- ğŸ” Automatic schema inference with confidence scoring
- ğŸ”¢ Numeric data generation with correlations
- ğŸ“ LLM-powered text generation
- ğŸ”’ Privacy-safe PII generation
- âœ… Multi-layer validation (quality + privacy)
- ğŸ¯ Domain-specific rules (fashion, finance, healthcare)
- ğŸ” Deterministic & reproducible (seeded)
- ğŸ“Š Multiple interfaces: CLI, API, Web UI

---

## Quick Start

### Installation

```bash
# Clone the repository
git clone <repo-url>
cd synthetic-data-platform

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Copy environment template
cp .env.example .env
# Edit .env with your settings (especially OPENAI_API_KEY if using LLM)
```

### Basic Usage

#### CLI

```bash
# Generate synthetic data from input CSV
python -m src.cli \
  --input data/sample_input.csv \
  --output data/output/synthetic.csv \
  --config config/default.yaml \
  --validate

# Use a different preset
python -m src.cli \
  --input data/sample_input.csv \
  --output data/output/synthetic.csv \
  --config config/analytics.yaml
```

#### API

```bash
# Start the API server
python -m src.api

# In another terminal, test the API
curl -X POST "http://localhost:8000/generate" \
  -F "file=@data/sample_input.csv" \
  -F "config_path=config/default.yaml"
```

#### Web UI

```bash
# Start Streamlit app
streamlit run src/streamlit_app.py
```

---

## Project Structure

```
synthetic-data-platform/
â”œâ”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ core/                 # Core orchestration
â”‚   â”‚   â”œâ”€â”€ config.py         # Configuration management
â”‚   â”‚   â”œâ”€â”€ orchestrator.py   # Main generation controller
â”‚   â”‚   â””â”€â”€ router.py         # Pipeline routing
â”‚   â”œâ”€â”€ schema/               # Schema inference
â”‚   â”‚   â”œâ”€â”€ profiler.py       # Column type inference
â”‚   â”‚   â”œâ”€â”€ types.py          # Column type definitions
â”‚   â”‚   â””â”€â”€ pii_detector.py   # PII detection
â”‚   â”œâ”€â”€ generators/           # Data generators
â”‚   â”‚   â”œâ”€â”€ numeric.py        # Numeric generation
â”‚   â”‚   â”œâ”€â”€ text.py           # Text generation (LLM)
â”‚   â”‚   â””â”€â”€ pii.py            # PII generation
â”‚   â”œâ”€â”€ validation/           # Quality & privacy checks
â”‚   â”‚   â”œâ”€â”€ quality.py        # Quality metrics
â”‚   â”‚   â””â”€â”€ privacy.py        # Privacy risk assessment
â”‚   â”œâ”€â”€ cli.py                # Command-line interface
â”‚   â”œâ”€â”€ api.py                # REST API
â”‚   â””â”€â”€ streamlit_app.py      # Web UI
â”œâ”€â”€ config/                   # Configuration presets
â”‚   â”œâ”€â”€ default.yaml
â”‚   â”œâ”€â”€ analytics.yaml
â”‚   â””â”€â”€ survey.yaml
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ knowledge/            # Domain knowledge files
â”‚   â””â”€â”€ sample_input.csv      # Example input
â”œâ”€â”€ tests/                    # Unit tests
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

---

## Configuration

The platform uses YAML configuration files with multiple presets:

- **default.yaml**: General-purpose, balanced settings
- **analytics.yaml**: Analytics/ML optimized (strict validation, numeric focus)
- **survey.yaml**: Survey responses (expressive text, conversational tone)

### Key Configuration Sections

```yaml
generation:
  rows: 1000              # Number of synthetic rows
  seed: 42                # Random seed for reproducibility

numeric:
  min: 0
  max: 100
  precision: 2
  allow_correlations: true

text:
  enabled: true
  model: gpt-4-turbo
  temperature: 0.7
  max_tokens: 256

pii:
  anonymize: true
  ensure_uniqueness: true

validation:
  quality:
    min_variance: 0.01
    min_unique_ratio: 0.05
  privacy:
    min_k_anonymity: 5
    max_uniqueness_ratio: 0.05
```

---

## Domain Knowledge

The platform supports domain-specific rules stored in `data/knowledge/`:

- **fashion/**: Product pricing, inventory rules, text guidelines
- **finance/**: Account balances, interest rates, transaction rules
- **healthcare/**: Vital signs, lab values, physiological limits

---

## Examples

### Generate Analytics Dataset

```bash
python -m src.cli \
  --input data/ecommerce_schema.csv \
  --output data/synthetic_analytics.csv \
  --config config/analytics.yaml \
  --validate
```

### Generate Survey Responses

```bash
python -m src.cli \
  --input data/survey_template.csv \
  --output data/synthetic_survey.csv \
  --config config/survey.yaml \
  --rows 5000
```

---

## API Reference

### POST /generate

Generate synthetic data from uploaded CSV.

**Request:**
```bash
curl -X POST "http://localhost:8000/generate" \
  -F "file=@input.csv" \
  -F "config_path=config/default.yaml" \
  -F "validate=true"
```

**Response:**
```json
{
  "data": [...],
  "validation": {
    "passed": true,
    "issues": []
  }
}
```

### POST /profile

Profile an input dataset (schema inference only).

---

## Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test file
pytest tests/test_generators.py
```

---

## Environment Variables

```bash
# Required for text generation
OPENAI_API_KEY=sk-...

# Optional
LOG_LEVEL=INFO
OUTPUT_PATH=data/output
VALIDATION_STRICT=true
```

---

## License

MIT

---

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

---

## Support

For issues and questions, please open a GitHub issue.
